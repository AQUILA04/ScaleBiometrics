# Story 2.3: Master Orchestrator (Kafka & Aggregation)

**Status:** Approved

## Story
**As a** Backend Developer,
**I want** to implement the Master Orchestrator service,
**so that** incoming deduplication requests from Kafka are dispatched to workers and results are aggregated.

## Acceptance Criteria
1. **Kafka Consumer**: The Master consumes "Deduplication Requests" from the `biometric.ingest` topic.
2. **Worker Discovery**: The Master knows the addresses of available Worker nodes (Static list for MVP).
3. **Dispatch Logic (Scatter)**:
    - Master sends the probe to *all* relevant workers via gRPC.
    - Uses Java 21 **Virtual Threads** (`StructuredTaskScope`) to handle these parallel gRPC calls efficiently.
4. **Aggregation Logic (Gather)**:
    - Collects results from all workers.
    - Sorts by score (descending).
    - Determines the global best match(es).
5. **Result Publishing**: Publishes the final decision (Match/No-Match) to a `biometric.result` topic.

## Tasks / Subtasks
- [ ] **Master Service Setup**
    - [ ] Initialize `apps/master`.
    - [ ] Add Kafka and gRPC Client dependencies.
- [ ] **Kafka Implementation**
    - [ ] Create Consumer Config for `biometric.ingest`.
    - [ ] Define JSON Payload for the event.
- [ ] **Orchestration Logic**
    - [ ] Implement `WorkerClient` (gRPC stub wrapper).
    - [ ] Implement `MatchingOrchestrator` service.
    - [ ] Use `try (var scope = new StructuredTaskScope.ShutdownOnFailure())` to fork gRPC calls.
    - [ ] Aggregate results.
- [ ] **Result Handling**
    - [ ] If max_score > Threshold -> MATCH_FOUND.
    - [ ] Else -> NO_MATCH.
    - [ ] Produce event to `biometric.result`.

## Dev Notes
* **Timeout Handling**: gRPC calls must have strict deadlines (e.g., 1.5s).
* **CRITICAL - Context Propagation**: The Master acts as the bridge. You MUST take the `TraceID` and `TenantID` from the Kafka Record Headers and pass them into the gRPC Metadata when calling Workers. If this chain breaks, observability is lost.
